{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project-model-text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJCEPAeTkC9u",
        "colab_type": "text"
      },
      "source": [
        "#Project Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vop_DLPmj3sZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import boto3\n",
        "import re\n",
        "from sagemaker import get_execution_role\n",
        "import sagemaker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow.keras as layers\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sagemaker.tensorflow.model import TensorFlowModel\n",
        "from sklearn.metrics import r2_score\n",
        "from keras.models import Sequential\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python.saved_model import builder\n",
        "from tensorflow.python.saved_model.signature_def_utils  import predict_signature_def\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from keras import backend as K\n",
        "bucket = sagemaker.Session().default_bucket()\n",
        "\n",
        "role = get_execution_role()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MMFzXg5kY_v",
        "colab_type": "text"
      },
      "source": [
        "Getting The Data from the local environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5uJQykIkYox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv(\"mushrooms.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSGYaOIvAEm",
        "colab_type": "text"
      },
      "source": [
        "#The data File guaranted to have no null values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhF2f64UvgSv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfCPl_-Nkjjk",
        "colab_type": "text"
      },
      "source": [
        "#Looking at the mushroom Data.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27ekSv1fksNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K66aE6dxktWL",
        "colab_type": "text"
      },
      "source": [
        "#number of unique vlaues at each cloumns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEP5elCelmtq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.nunique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_Lrm18Elo2h",
        "colab_type": "text"
      },
      "source": [
        "We see some data have more than 2 # of unique data - so we need to use get dummies - using HOT encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZmoTIrZqOBA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.get_dummies(df, columns=['cap-shape','cap-color','cap-surface','odor','gill-color','stalk-root','stalk-surface-above-ring',\n",
        "            'stalk-surface-below-ring','stalk-color-above-ring','stalk-color-below-ring','veil-color','ring-number','ring-type','spore-print-color',\n",
        "            'population','habitat'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucCZSkqCqU4V",
        "colab_type": "text"
      },
      "source": [
        "#Here we encoding the Binary features and the class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykZNnvKqqp0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "le=LabelEncoder()\n",
        "for item in df.columns:\n",
        "  df[item]=le.fit_transform(df[item])\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaXNmChXqr7C",
        "colab_type": "text"
      },
      "source": [
        "# we drop the target as y  from dataframe and the rest goes to x as features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiySCBUurDTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=df.drop(labels=['class'],axis=1)\n",
        "y=df[['class']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsW45wqrrE0R",
        "colab_type": "text"
      },
      "source": [
        "# Now we split the data to training and testing, 0.8 and 0.2 ratio respectively. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqYX5_udrple",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRTF746SrrSD",
        "colab_type": "text"
      },
      "source": [
        "#We are defining the model as Fucntion\n",
        "where the model is Sequential consist 3 Dense layers.\n",
        "The data shape (num of records , 112)\n",
        "activation is 'relu'\n",
        "and the last layer Sigmoid which make the output bettween 0 - 1 \n",
        "since this Problem Binary classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tR3X-XNarq4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32, activation = 'relu', input_dim = x_train.shape[1]))\n",
        "    model.add(Dense(64, activation = 'relu'))\n",
        "    model.add(Dense(1,  activation = 'sigmoid'))\n",
        "    model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucJwLFhOs8Wd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model=build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfdCW4gss-id",
        "colab_type": "text"
      },
      "source": [
        "#Now the fun begins with our Fiting method.\n",
        "we are showing the logs \"verbose=1\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v55-ccNNtD6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(x_train,y_train,\n",
        "          verbose=1,\n",
        "          epochs=20,\n",
        "          validation_split=.1\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uL107paPtqjS",
        "colab_type": "text"
      },
      "source": [
        "We Got 100% for the accuracy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wW1lM0ptaXy",
        "colab_type": "text"
      },
      "source": [
        "#Evaluating the Model using r2_score from the sikit learn Library.\n",
        "to see if the model overfiting or memorised the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORpwd4t7uBpV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r2_score(y_test,model.predict(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUaJHrvyut1c",
        "colab_type": "text"
      },
      "source": [
        "Oh Nice! our Model is Perfect!\n",
        "with 99% accuracy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfRVov-xww5I",
        "colab_type": "text"
      },
      "source": [
        "#We are ready to deploy the model to AWS cloud.\n",
        "we make the directory Named keras_model as the usual protocal. \n",
        "and we save the weights to the same path.\n",
        "then we write our model to Json."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v9kU_uOxIQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!mkdir \"keras_model\"\n",
        "save_path = \"./keras_model/\"\n",
        "\n",
        "model.save_weights(os.path.join(save_path,\"model-weights.h5\"))\n",
        "\n",
        "model_json = model.to_json()\n",
        "with open(os.path.join(save_path,\"model.json\"), \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpyEdFzGzk2F",
        "colab_type": "text"
      },
      "source": [
        "#opening the Json file and loding the model to the loaded_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb35an-AzncW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_file = open('keras_model/'+\\\n",
        "                 'model.json', 'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_json,custom_objects=\\\n",
        "        {\"GlorotUniform\": tf.keras.initializers.glorot_uniform})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ5q88RS0Dhk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loading Weights\n",
        "loaded_model.load_weights(\\\n",
        "    'keras_model/model-weights.h5')\n",
        "print(\"Loaded model from disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n3jUPUz0FZ7",
        "colab_type": "text"
      },
      "source": [
        "We make locally directory.\n",
        "and the expected path for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAyjtZ-P0TU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note: This directory structure will need to be followed - see notes \n",
        "# for the next section\n",
        "model_version = '1'\n",
        "export_dir = 'export/Servo/' + model_version"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU6XqCG40dCH",
        "colab_type": "text"
      },
      "source": [
        "deleting anything leaving in that path"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkgKtvF30dhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "shutil.rmtree(export_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROSMgM_E0nD5",
        "colab_type": "text"
      },
      "source": [
        "# Build the Protocol Buffer SavedModel at 'export_dir'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q352uGgw0mhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "build = builder.SavedModelBuilder(export_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Twpvbuc0yta",
        "colab_type": "text"
      },
      "source": [
        "# Creating prediction signature to be used by TensorFlow Serving Predict API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Apchw39e0wj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "signature = predict_signature_def(\n",
        "    inputs={\"inputs\": loaded_model.input}, \\\n",
        "    outputs={\"score\": loaded_model.output})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B3kE_k702D5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "with K.get_session() as sess:\n",
        "    # Save the meta graph and variables\n",
        "    build.add_meta_graph_and_variables(\n",
        "        sess=sess, tags=[tag_constants.SERVING], \\\n",
        "        signature_def_map={\"serving_default\": signature})\n",
        "    build.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3sL_J9L078B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with tarfile.open('model.tar.gz', mode='w:gz') as archive:\n",
        "    archive.add('export', recursive=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWcf5p7i1Jjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sagemaker_session = sagemaker.Session()\n",
        "inputs = sagemaker_session.upload_data(path='model.tar.gz', \\\n",
        "                key_prefix='model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ChQvkvp1XT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creating train.py\n",
        "!touch train.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "036UTFag1ah1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "sagemaker_model = TensorFlowModel(model_data = 's3://' + \\\n",
        "    sagemaker_session.default_bucket() + '/model/model.tar.gz',\n",
        "    role = role,\n",
        "    framework_version = '1.12',\n",
        "    entry_point = 'train.py')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-vP-Plv1mAB",
        "colab_type": "text"
      },
      "source": [
        "Deploying the model to the Cloud."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acY8q3Ye1hXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "predictor = sagemaker_model.deploy(initial_instance_count=1,\n",
        "                                   instance_type='ml.t2.medium')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d26yqSWe1uWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EndPoint Name\n",
        "predictor.endpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl8tHEOy1yfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "endpoint_name = \"From the previous EndPoint Name\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzNud2D91-VF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictor=sagemaker.tensorflow.model.TensorFlowPredictor(\\\n",
        "        endpoint_name, sagemaker_session)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqAjtCtR2EyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From inside the AWS \n",
        "client = boto3.client('runtime.sagemaker', region_name='us-east-1') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejj7cydW2KYW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Testing the deployed Predictor with dummiy data \n",
        "\n",
        "data = [[0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
        "       1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
        "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
        "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
        "       0, 0]]\n",
        "\n",
        "response = client.invoke_endpoint(EndpointName=endpoint_name, \\\n",
        "                                  Body=json.dumps(data))\n",
        "response_body = response[\"Body\"]\n",
        "print(json.loads(response_body.read())['outputs']['score']['floatVal'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtG0M79L2fVO",
        "colab_type": "text"
      },
      "source": [
        "And its ready to Go!"
      ]
    }
  ]
}